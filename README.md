# Transfer Learning / Fine-Tuning (PT-BR) â€” Notebook Original + Ajustes para CPU

Este repositÃ³rio traz o **notebook original** de Transfer Learning com Keras/TensorFlow, mantendo o conteÃºdo **intacto**, e adiciona **apenas**:
1. Uma seÃ§Ã£o **`introducao_br`** (PT-BR) no topo do notebook, explicando objetivos, como interpretar mÃ©tricas e dicas de prÃ¡tica.
2. Duas melhorias **para CPU** marcadas como **`[ALTERAÃ‡ÃƒO CPU]`**:
   - ForÃ§ar backend do Keras para **TensorFlow** e **ocultar GPUs** (inclusive DirectML no Windows) para execuÃ§Ã£o estÃ¡vel em **CPU**.
   - Aplicar **`prefetch(tf.data.AUTOTUNE)`** nos datasets, se jÃ¡ estiverem criados, para acelerar I/O em CPU.

> Nenhuma cÃ©lula original foi removida ou sobrescrita. As mudanÃ§as sÃ£o **adiÃ§Ãµes** e estÃ£o claramente comentadas.

---

## ğŸ§  O que o notebook faz
- Carrega um **modelo prÃ©-treinado** (ex.: `VGG16`) do Keras Applications.
- **Feature extraction**: congela o backbone e treina apenas a cabeÃ§a de classificaÃ§Ã£o.
- **Fine-tuning (opcional)**: libera um pequeno conjunto de camadas finais com **learning rate** reduzida.
- Exibe logs por Ã©poca: `accuracy`, `val_accuracy`, `loss`, `val_loss` e (em geral) plota curvas para anÃ¡lise.

### Como interpretar os resultados
- **AcurÃ¡cia** (`accuracy`, `val_accuracy`): proporÃ§Ã£o de acertos no **treino** e **validaÃ§Ã£o**.
- **Perda** (`loss`, `val_loss`): valor da funÃ§Ã£o de custo. O ideal Ã© que **ambas** diminuam.
- **Overfitting**: se `loss` (treino) â†“ mas `val_loss` â†‘ de forma consistente, ajuste regularizaÃ§Ã£o/augmentation, reduza fine-tuning ou **pare antes** (EarlyStopping).
- **Transfer learning** Ã© especialmente Ãºtil com poucos dados â€” os primeiros *epochs* jÃ¡ devem mostrar melhora de `val_accuracy`.

---

## ğŸš€ Como rodar (Google Colab ou local)

### OpÃ§Ã£o A â€” Google Colab (recomendado para comeÃ§ar)
1. Envie o notebook **`transfer_learning_ptbr_cpu.ipynb`** para o Colab.
2. (Se necessÃ¡rio) Instale dependÃªncias no inÃ­cio:
   ```python
   !pip -q install "tensorflow==2.17.*" "keras>=3,<4" "numpy==1.26.4" "matplotlib"
   ```
3. Execute as cÃ©lulas na ordem. As duas cÃ©lulas de **`[ALTERAÃ‡ÃƒO CPU]`** estÃ£o no topo.

### OpÃ§Ã£o B â€” Local (Windows/Conda)
```powershell
conda create -y -n tf311 -c conda-forge python=3.11 jupyterlab notebook sqlite
conda activate tf311
python -m pip install --upgrade pip
python -m pip install -r requirements_cpu.txt

# evitar conflito com pacotes do User Site (opcional, recomendado)
conda env config vars set PYTHONNOUSERSITE=1
conda deactivate && conda activate tf311

# registrar kernel no Jupyter
python -m ipykernel install --user --name tf311 --display-name "Python (tf311)"
jupyter notebook
```
No notebook, selecione o kernel **Python (tf311)**.  
Confirme dentro da primeira cÃ©lula: `TF: 2.17.*` e a lista de dispositivos **sem GPU** (CPU forÃ§ada).

---

## ğŸ§© Dataset
O notebook original foi escrito para **imagens** e utiliza prÃ©-processamento compatÃ­vel com `VGG16`.  
VocÃª pode usar:
- **MNIST** (conforme o link do desafio).
- **Cats vs Dogs** (binÃ¡rio).
- **Seu prÃ³prio dataset** de 2 classes (ex.: seus pets, objetos, etc.).

> Se usar pastas no formato `train/` e `val/`, ajuste os trechos de carregamento conforme o original (ex.: `ImageDataGenerator` ou APIs equivalentes do Keras).

---

## âš™ï¸ Ajustes de desempenho (CPU)
- **Batch**: use 8â€“32. Batches maiores em CPU podem **piorar** o tempo/epoch.
- **Imagem**: 160â€“224 px (conforme o modelo prÃ©-treinado escolhido).
- **Prefetch**: jÃ¡ incluÃ­do pela alteraÃ§Ã£o **`[ALTERAÃ‡ÃƒO CPU]`** (sÃ³ se os datasets existirem).
- **Fine-tuning**: comece **desligado** (sÃ³ feature extraction) e ative **poucas** camadas finais quando a validaÃ§Ã£o **estabilizar**.
- **Callbacks**: use `EarlyStopping` e `ModelCheckpoint` quando possÃ­vel.

---

## ğŸ§ª MÃ©tricas & DiagnÃ³stico
- Acompanhe `val_accuracy` e `val_loss`. Se ficarem **estÃ¡veis** ou piorarem, ajuste LR/camadas/augmentation.
- Compare **baseline do zero** vs **transfer learning**: o TL tende a convergir mais rÃ¡pido e com melhor `val_accuracy` em poucos dados.

---

## ğŸ“¦ Arquivos do repositÃ³rio
```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements_cpu.txt
â””â”€â”€ transfer_learning_ptbr_cpu.ipynb
```
- `transfer_learning_ptbr_cpu.ipynb`: notebook original + **`introducao_br`** + **`[ALTERAÃ‡ÃƒO CPU]`**.
- `requirements_cpu.txt`: versÃµes pinadas para evitar conflitos (NumPy 1.26.x, TF 2.17.x, Keras 3).

---

## âœ… Checklist (DIO)
- [ ] Executar o notebook e documentar **sua experiÃªncia** (o que mudou, resultados, prints).
- [ ] Preencher este `README.md` com **prints** (pasta `/images`) e **observaÃ§Ãµes pessoais**.
- [ ] Publicar o repositÃ³rio no GitHub e enviar o link na plataforma.
- [ ] (Opcional) Usar seu prÃ³prio dataset de 2 classes.

---

## ğŸ“œ LicenÃ§a
MIT â€” sinta-se Ã  vontade para usar, adaptar e compartilhar.
